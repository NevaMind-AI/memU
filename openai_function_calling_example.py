#!/usr/bin/env python3
"""
OpenAIå®˜æ–¹Function Callingç¤ºä¾‹

å±•ç¤ºå¦‚ä½•æŒ‰ç…§OpenAIæœ€ä½³å®è·µä½¿ç”¨Memory Agent
"""

import json
from memu.llm import OpenAIClient
from memu.memory import MemoryAgent

def main():
    """OpenAI Function Callingæœ€ä½³å®è·µç¤ºä¾‹"""
    
    print("ğŸš€ OpenAIå®˜æ–¹Function Callingç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–ç»„ä»¶
    llm_client = OpenAIClient(model="gpt-4o-mini")
    memory_agent = MemoryAgent(llm_client=llm_client, memory_dir="memory")
    
    # 2. è·å–OpenAIå…¼å®¹çš„å‡½æ•°å®šä¹‰
    function_schemas = memory_agent.get_functions_schema()
    
    print(f"ğŸ“‹ å¯ç”¨å‡½æ•°: {len(function_schemas)} ä¸ª")
    for schema in function_schemas:
        print(f"  â€¢ {schema['name']}: {schema['description']}")
    print()
    
    # 3. æ„å»ºå¯¹è¯ - ä½¿ç”¨æ˜ç¡®çš„æŒ‡ä»¤è§¦å‘å‡½æ•°è°ƒç”¨
    messages = [
        {
            "role": "system",
            "content": """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨è®°å¿†åŠŸèƒ½æ¥å­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯ã€‚
            
å½“ç”¨æˆ·è¦æ±‚ä½ è®°ä½ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ add_memory å‡½æ•°ã€‚
å½“ç”¨æˆ·è¯¢é—®ä¹‹å‰çš„ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ search_memory æˆ– read_memory å‡½æ•°ã€‚
å½“ç”¨æˆ·è¦æ±‚æ›´æ–°ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ update_memory å‡½æ•°ã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å‡½æ•°è°ƒç”¨ã€‚"""
        },
        {
            "role": "user",
            "content": "è¯·å¸®æˆ‘è®°ä½ï¼šæˆ‘å«Aliceï¼Œ25å²ï¼Œæ˜¯ä¸€åäº§å“ç»ç†ï¼Œå–œæ¬¢é˜…è¯»å’Œæ—…è¡Œã€‚"
        }
    ]
    
    # 4. æŒ‰ç…§OpenAIå®˜æ–¹æ ¼å¼è°ƒç”¨
    def process_conversation(messages, max_iterations=5):
        """å¤„ç†å¯¹è¯ï¼Œæ”¯æŒå¤šè½®å‡½æ•°è°ƒç”¨"""
        
        for iteration in range(max_iterations):
            print(f"\nğŸ”„ è¿­ä»£ {iteration + 1}")
            print("-" * 20)
            
            # è°ƒç”¨OpenAI API
            response = llm_client.chat_completion(
                messages=messages,
                tools=[{"type": "function", "function": schema} for schema in function_schemas],
                tool_choice="auto",
                temperature=0.3
            )
            
            if not response.success:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.error}")
                break
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
            assistant_message = {
                "role": "assistant",
                "content": response.content
            }
            
            # å¤„ç†å‡½æ•°è°ƒç”¨
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"ğŸ› ï¸ æ£€æµ‹åˆ° {len(response.tool_calls)} ä¸ªå‡½æ•°è°ƒç”¨")
                
                # æ·»åŠ å‡½æ•°è°ƒç”¨åˆ°åŠ©æ‰‹æ¶ˆæ¯
                assistant_message["tool_calls"] = response.tool_calls
                messages.append(assistant_message)
                
                # æ‰§è¡Œæ¯ä¸ªå‡½æ•°è°ƒç”¨
                for tool_call in response.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)
                    
                    print(f"  ğŸ“ è°ƒç”¨: {function_name}")
                    print(f"  ğŸ“ å‚æ•°: {json.dumps(arguments, ensure_ascii=False, indent=2)}")
                    
                    # æ‰§è¡Œå‡½æ•°
                    result = memory_agent.call_function(function_name, arguments)
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                    tool_message = {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(result, ensure_ascii=False)
                    }
                    messages.append(tool_message)
                    
                    print(f"  âœ… ç»“æœ: {'æˆåŠŸ' if result.get('success') else 'å¤±è´¥'}")
                    if result.get('success'):
                        if 'file_path' in result:
                            print(f"  ğŸ“ æ–‡ä»¶: {result['file_path']}")
                    else:
                        print(f"  âŒ é”™è¯¯: {result.get('error')}")
                
            else:
                # æ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œæ·»åŠ å›å¤å¹¶ç»“æŸ
                messages.append(assistant_message)
                if response.content:
                    print(f"ğŸ’¬ åŠ©æ‰‹å›å¤: {response.content}")
                break
        
        return messages
    
    # 5. å¤„ç†ç¬¬ä¸€è½®å¯¹è¯
    print("ğŸ’¬ ç¬¬ä¸€è½®å¯¹è¯ï¼šå­˜å‚¨ä¿¡æ¯")
    messages = process_conversation(messages)
    
    # 6. æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œæµ‹è¯•
    print("\n" + "=" * 50)
    print("ğŸ’¬ ç¬¬äºŒè½®å¯¹è¯ï¼šæ£€ç´¢ä¿¡æ¯")
    
    messages.append({
        "role": "user",
        "content": "Aliceçš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿå¥¹æœ‰ä»€ä¹ˆçˆ±å¥½ï¼Ÿ"
    })
    
    messages = process_conversation(messages)
    
    # 7. æ¼”ç¤ºæ›´æ–°åŠŸèƒ½
    print("\n" + "=" * 50)
    print("ğŸ’¬ ç¬¬ä¸‰è½®å¯¹è¯ï¼šæ›´æ–°ä¿¡æ¯")
    
    messages.append({
        "role": "user", 
        "content": "Aliceç°åœ¨26å²äº†ï¼Œè¯·æ›´æ–°å¥¹çš„å¹´é¾„ä¿¡æ¯ã€‚"
    })
    
    messages = process_conversation(messages)
    
    print("\nğŸ‰ ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“‹ æ€»ç»“:")
    print("âœ… ä½¿ç”¨OpenAIå®˜æ–¹function callingæ ¼å¼")
    print("âœ… æ”¯æŒå¤šè½®å‡½æ•°è°ƒç”¨")
    print("âœ… æ­£ç¡®å¤„ç†å·¥å…·è°ƒç”¨å’Œç»“æœ")
    print("âœ… ç»´æŠ¤å®Œæ•´çš„å¯¹è¯å†å²")
    print("âœ… ç¬¦åˆOpenAIæœ€ä½³å®è·µ")

if __name__ == "__main__":
    main() 