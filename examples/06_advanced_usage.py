#!/usr/bin/env python3
"""
06_advanced_usage.py

PersonaLabé«˜çº§ç”¨æ³•ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ï¼š
1. æ‰¹é‡å¤„ç†å¤§é‡å¯¹è¯æ•°æ®
2. å¤šä»£ç†åä½œå’ŒçŸ¥è¯†å…±äº«
3. é«˜çº§åˆ†æå’Œæ€§èƒ½ä¼˜åŒ–
4. ä¼ä¸šçº§åº”ç”¨åœºæ™¯
"""

import sys
from pathlib import Path
import time
import json
import random
from typing import List, Dict, Any

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from personalab.memory import MemoryClient
from personalab.memo import ConversationManager


class AdvancedPersonaLabManager:
    """é«˜çº§PersonaLabç®¡ç†å™¨"""
    
    def __init__(self, memory_db: str, conversation_db: str):
        self.memory_manager = MemoryClient(db_path=memory_db)
        self.conversation_manager = ConversationManager(
            db_path=conversation_db,
            enable_embeddings=True,
            embedding_provider="auto"
        )
        self.agents = {}
        
    def create_agent_team(self, agent_configs: List[Dict]):
        """åˆ›å»ºä»£ç†å›¢é˜Ÿ"""
        for config in agent_configs:
            agent_id = config['agent_id']
            memory = self.memory_manager.get_memory_by_agent(agent_id)
            memory.update_profile(config['profile'])
            
            if config.get('initial_events'):
                memory.update_events(config['initial_events'])
            
            if config.get('initial_insights'):
                memory.update_tom(config['initial_insights'])
            
            self.agents[agent_id] = {
                'memory': memory,
                'config': config,
                'stats': {'conversations': 0, 'messages': 0}
            }
            
            self.memory_manager.database.save_memory(memory)
        
        return self.agents
    
    def batch_process_conversations(self, conversations_data: List[Dict]):
        """æ‰¹é‡å¤„ç†å¯¹è¯æ•°æ®"""
        
        results = []
        errors = []
        
        for conv_data in conversations_data:
            try:
                start_time = time.time()
                
                conversation = self.conversation_manager.record_conversation(
                    agent_id=conv_data['agent_id'],
                    user_id=conv_data['user_id'],
                    messages=conv_data['messages'],
                    session_id=conv_data.get('session_id'),
                    enable_vectorization=conv_data.get('enable_vectorization', True)
                )
                
                processing_time = time.time() - start_time
                
                # æ›´æ–°ä»£ç†ç»Ÿè®¡
                if conv_data['agent_id'] in self.agents:
                    agent = self.agents[conv_data['agent_id']]
                    agent['stats']['conversations'] += 1
                    agent['stats']['messages'] += len(conv_data['messages'])
                
                results.append({
                    'success': True,
                    'conversation_id': conversation.conversation_id,
                    'agent_id': conversation.agent_id,
                    'user_id': conversation.user_id,
                    'turn_count': conversation.turn_count,
                    'processing_time': processing_time
                })
                
            except Exception as e:
                errors.append({
                    'success': False,
                    'error': str(e),
                    'conv_data': conv_data
                })
        
        return results, errors
    
    def knowledge_transfer(self, source_agent: str, target_agent: str, topic_keywords: List[str]):
        """ä»£ç†é—´çŸ¥è¯†è½¬ç§»"""
        
        transferred_knowledge = {
            'events': [],
            'insights': [],
            'conversations': []
        }
        
        for keyword in topic_keywords:
            results = self.conversation_manager.search_similar_conversations(
                agent_id=source_agent,
                query=keyword,
                limit=3,
                similarity_threshold=0.7
            )
            
            for result in results:
                conversation_summary = f"ä»{source_agent}å­¦ä¹ : {result['summary']}"
                transferred_knowledge['conversations'].append({
                    'summary': conversation_summary,
                    'similarity': result['similarity_score'],
                    'topic': keyword
                })
        
        # æ›´æ–°ç›®æ ‡ä»£ç†çš„çŸ¥è¯†
        if target_agent in self.agents:
            target_memory = self.agents[target_agent]['memory']
            
            # æ·»åŠ å­¦ä¹ äº‹ä»¶
            learning_events = [
                f"ä»ä»£ç†{source_agent}å­¦ä¹ äº†å…³äº{keyword}çš„çŸ¥è¯†" 
                for keyword in topic_keywords
            ]
            target_memory.update_events(learning_events)
            transferred_knowledge['events'] = learning_events
            
            # æ·»åŠ æ´å¯Ÿ
            learning_insights = [
                f"é€šè¿‡ä»£ç†é—´çŸ¥è¯†å…±äº«ï¼ŒæŒæ¡äº†{source_agent}åœ¨{keyword}æ–¹é¢çš„ç»éªŒ"
                for keyword in topic_keywords
            ]
            target_memory.update_tom(learning_insights)
            transferred_knowledge['insights'] = learning_insights
            
            # ä¿å­˜æ›´æ–°
            self.memory_manager.database.save_memory(target_memory)
        
        return transferred_knowledge
    
    def generate_agent_report(self, agent_id: str):
        """ç”Ÿæˆä»£ç†è¯¦ç»†æŠ¥å‘Š"""
        
        if agent_id not in self.agents:
            return None
        
        agent = self.agents[agent_id]
        memory = agent['memory']
        
        report = {
            'agent_id': agent_id,
            'profile': memory.get_profile_content(),
            'stats': agent['stats'].copy()
        }
        
        # å¯¹è¯å†å²ç»Ÿè®¡
        conversation_history = self.conversation_manager.get_conversation_history(
            agent_id=agent_id,
            limit=1000
        )
        
        if conversation_history:
            unique_users = set(conv['user_id'] for conv in conversation_history)
            report['user_stats'] = {
                'unique_users': len(unique_users),
                'total_conversations': len(conversation_history),
                'avg_conversations_per_user': len(conversation_history) / len(unique_users) if unique_users else 0
            }
        
        # å†…å­˜åˆ†æ
        events = memory.get_event_content()
        insights = memory.get_tom_content()
        
        report['memory_analysis'] = {
            'total_events': len(events),
            'total_insights': len(insights),
            'recent_events': events[-3:] if events else [],
            'recent_insights': insights[-2:] if insights else []
        }
        
        return report
    
    def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        self.memory_manager.database.close()
        self.conversation_manager.close()


def generate_mock_conversations(num_conversations: int = 20) -> List[Dict]:
    """ç”Ÿæˆæ¨¡æ‹Ÿå¯¹è¯æ•°æ®"""
    
    conversation_templates = [
        {
            "topic": "Pythonç¼–ç¨‹",
            "questions": ["å¦‚ä½•å­¦ä¹ Pythonï¼Ÿ", "PythonåŸºç¡€è¯­æ³•ï¼Ÿ"],
            "responses": ["Pythonæ˜¯å¾ˆå¥½çš„å…¥é—¨è¯­è¨€", "Pythonè¯­æ³•ç®€æ´æ˜“æ‡‚"]
        },
        {
            "topic": "æœºå™¨å­¦ä¹ ", 
            "questions": ["ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "å¦‚ä½•é€‰æ‹©ç®—æ³•ï¼Ÿ"],
            "responses": ["æœºå™¨å­¦ä¹ è®©è®¡ç®—æœºä»æ•°æ®å­¦ä¹ ", "ç®—æ³•é€‰æ‹©çœ‹é—®é¢˜ç±»å‹"]
        }
    ]
    
    conversations = []
    users = [f"user_{i:03d}" for i in range(1, 11)]
    agents = ["python_tutor", "ml_expert", "general_assistant"]
    
    for i in range(num_conversations):
        template = random.choice(conversation_templates)
        user_id = random.choice(users)
        agent_id = random.choice(agents)
        
        messages = []
        for j in range(2):  # 2è½®å¯¹è¯
            question = random.choice(template["questions"])
            response = random.choice(template["responses"])
            
            messages.extend([
                {"role": "user", "content": question},
                {"role": "assistant", "content": response}
            ])
        
        conversations.append({
            "agent_id": agent_id,
            "user_id": user_id,
            "messages": messages,
            "session_id": f"session_{i:03d}",
            "enable_vectorization": True
        })
    
    return conversations


def main():
    print("=== PersonaLab é«˜çº§ç”¨æ³•ç¤ºä¾‹ ===\n")
    
    # 1. åˆå§‹åŒ–é«˜çº§ç®¡ç†å™¨
    print("1. åˆå§‹åŒ–é«˜çº§ç®¡ç†å™¨...")
    
    manager = AdvancedPersonaLabManager(
        memory_db="advanced_memory.db",
        conversation_db="advanced_conversations.db"
    )
    
    print("âœ… é«˜çº§ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    print()
    
    # 2. åˆ›å»ºä»£ç†å›¢é˜Ÿ
    print("2. åˆ›å»ºä¸“ä¸šä»£ç†å›¢é˜Ÿ...")
    
    agent_configs = [
        {
            "agent_id": "python_tutor",
            "profile": "æˆ‘æ˜¯ä¸“ä¸šçš„Pythonç¼–ç¨‹å¯¼å¸ˆï¼Œä¸“æ³¨äºæ•™æˆPythonè¯­è¨€å’Œç¼–ç¨‹åŸºç¡€ã€‚",
            "initial_events": ["ä¸“æ³¨äºPythonæ•™å­¦"],
            "initial_insights": ["å­¦ç”Ÿéœ€è¦å¾ªåºæ¸è¿›çš„å­¦ä¹ "]
        },
        {
            "agent_id": "ml_expert", 
            "profile": "æˆ‘æ˜¯æœºå™¨å­¦ä¹ ä¸“å®¶ï¼Œä¸“é—¨æŒ‡å¯¼æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ•°æ®ç§‘å­¦é¡¹ç›®ã€‚",
            "initial_events": ["ä¸“æ³¨äºMLæ•™å­¦"],
            "initial_insights": ["ç†è®ºä¸å®è·µç»“åˆé‡è¦"]
        },
        {
            "agent_id": "general_assistant",
            "profile": "æˆ‘æ˜¯é€šç”¨AIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”å„ç§æŠ€æœ¯é—®é¢˜ã€‚",
            "initial_events": ["æä¾›é€šç”¨æŠ€æœ¯æ”¯æŒ"],
            "initial_insights": ["ç”¨æˆ·é—®é¢˜å¤šæ ·åŒ–"]
        }
    ]
    
    agents = manager.create_agent_team(agent_configs)
    print(f"âœ… åˆ›å»ºäº† {len(agents)} ä¸ªä¸“ä¸šä»£ç†:")
    for agent_id, agent_info in agents.items():
        print(f"   - {agent_id}: {agent_info['config']['profile'][:50]}...")
    print()
    
    # 3. æ‰¹é‡å¤„ç†å¯¹è¯
    print("3. æ‰¹é‡å¤„ç†å¯¹è¯æ•°æ®...")
    
    mock_conversations = generate_mock_conversations(num_conversations=15)
    print(f"   ç”Ÿæˆäº† {len(mock_conversations)} ä¸ªæ¨¡æ‹Ÿå¯¹è¯")
    
    start_time = time.time()
    results, errors = manager.batch_process_conversations(mock_conversations)
    processing_time = time.time() - start_time
    
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ:")
    print(f"   æˆåŠŸå¤„ç†: {len(results)} ä¸ªå¯¹è¯")
    print(f"   å¤„ç†å¤±è´¥: {len(errors)} ä¸ªå¯¹è¯")
    print(f"   æ€»å¤„ç†æ—¶é—´: {processing_time:.2f}s")
    print()
    
    # 4. ä»£ç†é—´çŸ¥è¯†è½¬ç§»
    print("4. ä»£ç†é—´çŸ¥è¯†è½¬ç§»...")
    
    print(f"\nğŸ“š çŸ¥è¯†è½¬ç§»: python_tutor â†’ general_assistant")
    
    knowledge = manager.knowledge_transfer(
        source_agent="python_tutor",
        target_agent="general_assistant",
        topic_keywords=["Python", "ç¼–ç¨‹"]
    )
    
    print(f"âœ… è½¬ç§»å®Œæˆ:")
    print(f"   æ–°å¢äº‹ä»¶: {len(knowledge['events'])} ä¸ª")
    print(f"   æ–°å¢æ´å¯Ÿ: {len(knowledge['insights'])} ä¸ª")
    print(f"   ç›¸å…³å¯¹è¯: {len(knowledge['conversations'])} ä¸ª")
    print()
    
    # 5. ç”Ÿæˆä»£ç†æŠ¥å‘Š
    print("5. ç”Ÿæˆè¯¦ç»†ä»£ç†æŠ¥å‘Š...")
    
    for agent_id in ["python_tutor", "general_assistant"]:
        print(f"\nğŸ“Š ä»£ç†æŠ¥å‘Š: {agent_id}")
        print("-" * 30)
        
        report = manager.generate_agent_report(agent_id)
        
        if report:
            print(f"Profile: {report['profile'][:60]}...")
            
            if 'user_stats' in report:
                stats = report['user_stats']
                print(f"ç”¨æˆ·ç»Ÿè®¡: {stats['unique_users']} ç”¨æˆ·, {stats['total_conversations']} å¯¹è¯")
            
            memory_analysis = report['memory_analysis']
            print(f"å†…å­˜çŠ¶æ€: {memory_analysis['total_events']} äº‹ä»¶, {memory_analysis['total_insights']} æ´å¯Ÿ")
    
    # 6. æ€§èƒ½æµ‹è¯•
    print("\n6. æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    benchmark_queries = ["Python", "æœºå™¨å­¦ä¹ ", "ç¼–ç¨‹"]
    search_times = []
    
    for query in benchmark_queries:
        start_time = time.time()
        results = manager.conversation_manager.search_similar_conversations(
            agent_id="python_tutor",
            query=query,
            limit=5,
            similarity_threshold=0.5
        )
        search_time = time.time() - start_time
        search_times.append(search_time)
        
        print(f"   æŸ¥è¯¢ '{query}': {len(results)} ç»“æœ, {search_time:.3f}s")
    
    print(f"âœ… æœç´¢æ€§èƒ½æ€»ç»“:")
    print(f"   å¹³å‡æœç´¢æ—¶é—´: {sum(search_times)/len(search_times):.3f}s")
    
    # 7. æ¸…ç†èµ„æº
    print("\n7. æ¸…ç†èµ„æº...")
    manager.close()
    print("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    print("\n=== ç¤ºä¾‹å®Œæˆ ===")
    print("\nğŸ’¡ å­¦åˆ°çš„çŸ¥è¯†ç‚¹:")
    print("1. âœ… æ‰¹é‡å¤„ç†å¤§é‡å¯¹è¯æ•°æ®çš„æ–¹æ³•")
    print("2. âœ… å¤šä»£ç†åä½œå’ŒçŸ¥è¯†è½¬ç§»")
    print("3. âœ… è¯¦ç»†çš„åˆ†ææŠ¥å‘Šç”Ÿæˆ")
    print("4. âœ… æ€§èƒ½ä¼˜åŒ–å’Œä¼ä¸šçº§åº”ç”¨")


if __name__ == "__main__":
    main() 