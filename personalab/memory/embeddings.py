"""
Embedding generation and management module for PersonaLab.

Provides text-to-vector conversion functionality for semantic search and 
conversation similarity matching.
"""

import json
import hashlib
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Union
from datetime import datetime


class BaseEmbeddingProvider(ABC):
    """Abstract base class for embedding providers."""
    
    @abstractmethod
    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding vector for given text."""
        pass
    
    @abstractmethod
    def get_embedding_dimension(self) -> int:
        """Get the dimension of embeddings generated by this provider."""
        pass
    
    @property
    @abstractmethod
    def model_name(self) -> str:
        """Get the name of the embedding model."""
        pass


class OpenAIEmbeddingProvider(BaseEmbeddingProvider):
    """OpenAI-based embedding provider."""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "text-embedding-ada-002"):
        """
        Initialize OpenAI embedding provider.
        
        Args:
            api_key: OpenAI API key (optional, can use environment variable)
            model: OpenAI embedding model name
        """
        self.model = model
        self._client = None
        self.api_key = api_key
    
    def _get_client(self):
        """Lazy initialization of OpenAI client."""
        if self._client is None:
            try:
                import openai
                import os
                
                api_key = self.api_key or os.getenv("OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("OpenAI API key not provided")
                
                self._client = openai.OpenAI(api_key=api_key)
            except ImportError:
                raise ImportError("OpenAI library not installed. Run: pip install openai")
        
        return self._client
    
    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding using OpenAI API."""
        try:
            client = self._get_client()
            response = client.embeddings.create(
                model=self.model,
                input=text.replace("\n", " ")
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"Error generating OpenAI embedding: {e}")
            # Return zero vector as fallback
            return [0.0] * self.get_embedding_dimension()
    
    def get_embedding_dimension(self) -> int:
        """Get embedding dimension for the model."""
        if "ada-002" in self.model:
            return 1536
        elif "ada-001" in self.model:
            return 1024
        else:
            return 1536  # Default
    
    @property
    def model_name(self) -> str:
        return f"openai-{self.model}"


class SentenceTransformerProvider(BaseEmbeddingProvider):
    """Sentence Transformers-based embedding provider."""
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialize Sentence Transformer provider.
        
        Args:
            model_name: Sentence transformer model name
        """
        self.model_name_str = model_name
        self._model = None
    
    def _get_model(self):
        """Lazy initialization of sentence transformer model."""
        if self._model is None:
            try:
                from sentence_transformers import SentenceTransformer
                self._model = SentenceTransformer(self.model_name_str)
            except ImportError:
                raise ImportError("Sentence Transformers library not installed. Run: pip install sentence-transformers")
        
        return self._model
    
    def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding using Sentence Transformers."""
        try:
            model = self._get_model()
            embedding = model.encode([text])[0]
            return embedding.tolist()
        except Exception as e:
            print(f"Error generating Sentence Transformer embedding: {e}")
            return [0.0] * self.get_embedding_dimension()
    
    def get_embedding_dimension(self) -> int:
        """Get embedding dimension."""
        if "MiniLM-L6-v2" in self.model_name_str:
            return 384
        elif "MiniLM-L12-v2" in self.model_name_str:
            return 384
        elif "mpnet-base-v2" in self.model_name_str:
            return 768
        else:
            return 384  # Default
    
    @property
    def model_name(self) -> str:
        return f"sentence-transformers-{self.model_name_str}"


class SimpleEmbeddingProvider(BaseEmbeddingProvider):
    """Simple fallback embedding provider using basic text features."""
    
    def generate_embedding(self, text: str) -> List[float]:
        """Generate simple embedding based on text features."""
        # Very basic embedding based on text statistics
        words = text.lower().split()
        
        features = [
            len(text),                           # Text length
            len(words),                          # Word count
            len(set(words)),                     # Unique word count
            sum(1 for c in text if c.isalpha()), # Letter count
            sum(1 for c in text if c.isdigit()), # Digit count
            text.count('?'),                     # Question marks
            text.count('!'),                     # Exclamation marks
            text.count('.'),                     # Periods
        ]
        
        # Normalize features to 0-1 range and pad to fixed dimension
        max_vals = [1000, 200, 100, 800, 100, 10, 10, 20]
        normalized = [min(f / m, 1.0) for f, m in zip(features, max_vals)]
        
        # Pad to 32 dimensions with zeros
        while len(normalized) < 32:
            normalized.append(0.0)
        
        return normalized[:32]
    
    def get_embedding_dimension(self) -> int:
        return 32
    
    @property
    def model_name(self) -> str:
        return "simple-text-features"


class EmbeddingManager:
    """Manager for handling embeddings with multiple providers."""
    
    def __init__(self, provider: Optional[BaseEmbeddingProvider] = None):
        """
        Initialize embedding manager.
        
        Args:
            provider: Embedding provider (defaults to simple provider)
        """
        self.provider = provider or self._get_default_provider()
    
    def _get_default_provider(self) -> BaseEmbeddingProvider:
        """Get default embedding provider based on available libraries."""
        try:
            # Try OpenAI first if API key is available
            import os
            if os.getenv("OPENAI_API_KEY"):
                return OpenAIEmbeddingProvider()
        except ImportError:
            pass
        
        try:
            # Try Sentence Transformers
            return SentenceTransformerProvider()
        except ImportError:
            pass
        
        # Fallback to simple provider
        return SimpleEmbeddingProvider()
    
    def generate_conversation_embedding(self, conversation: List[Dict[str, str]]) -> List[float]:
        """
        Generate embedding for entire conversation.
        
        Args:
            conversation: List of conversation messages
            
        Returns:
            List[float]: Conversation embedding vector
        """
        # Combine all conversation content into single text
        conversation_text = ""
        for message in conversation:
            role = message.get('role', '')
            content = message.get('content', '')
            conversation_text += f"{role}: {content}\n"
        
        return self.provider.generate_embedding(conversation_text.strip())
    
    def generate_message_embedding(self, message: Dict[str, str]) -> List[float]:
        """
        Generate embedding for single message.
        
        Args:
            message: Single conversation message
            
        Returns:
            List[float]: Message embedding vector
        """
        content = message.get('content', '')
        return self.provider.generate_embedding(content)
    
    def generate_memory_embedding(self, memory_content: str) -> List[float]:
        """
        Generate embedding for memory content.
        
        Args:
            memory_content: Memory content text
            
        Returns:
            List[float]: Memory embedding vector
        """
        return self.provider.generate_embedding(memory_content)
    
    def batch_generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generate embeddings for multiple texts.
        
        Args:
            texts: List of text strings
            
        Returns:
            List[List[float]]: List of embedding vectors
        """
        return [self.provider.generate_embedding(text) for text in texts]
    
    @property
    def model_name(self) -> str:
        """Get the name of the current embedding model."""
        return self.provider.model_name
    
    @property
    def embedding_dimension(self) -> int:
        """Get the dimension of embeddings."""
        return self.provider.get_embedding_dimension()


def create_embedding_manager(
    provider_type: str = "auto",
    **kwargs
) -> EmbeddingManager:
    """
    Create embedding manager with specified provider.
    
    Args:
        provider_type: Type of provider ('openai', 'sentence-transformers', 'simple', 'auto')
        **kwargs: Additional arguments for the provider
        
    Returns:
        EmbeddingManager: Configured embedding manager
    """
    if provider_type == "auto":
        return EmbeddingManager()
    elif provider_type == "openai":
        provider = OpenAIEmbeddingProvider(**kwargs)
    elif provider_type == "sentence-transformers":
        provider = SentenceTransformerProvider(**kwargs)
    elif provider_type == "simple":
        provider = SimpleEmbeddingProvider()
    else:
        raise ValueError(f"Unknown provider type: {provider_type}")
    
    return EmbeddingManager(provider) 