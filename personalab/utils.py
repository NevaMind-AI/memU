#!/usr/bin/env python3
"""
PersonaLab å·¥å…·æ¨¡å—

åŒ…å«PersonaLabé¡¹ç›®ä¸­é‡å¤ä½¿ç”¨çš„é€šç”¨å‡½æ•°å’Œå·¥å…·ï¼Œæä¾›ï¼š
1. å¯¹è¯å¤„ç†å’Œåˆ†æå·¥å…·
2. Memoryç®¡ç†å·¥å…·
3. AIå“åº”æ¨¡æ‹Ÿå’Œå­¦ä¹ åŠŸèƒ½

ä½œè€…: PersonaLabå›¢é˜Ÿ
"""

import re
from datetime import datetime
from typing import Any, Dict, List, Optional

from .config.database import get_database_manager
from personalab.memo import ConversationManager
from personalab.memory import Memory, MemoryClient


def simulate_ai_response(
    memory: Memory, user_message: str, conversation_history: Optional[List[Dict[str, Any]]] = None
) -> str:
    """
    æ¨¡æ‹ŸAIå“åº”ï¼ˆç”¨äºæ¼”ç¤ºï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨çœŸå®çš„LLM APIï¼‰

    Args:
        memory: Memoryå¯¹è±¡ï¼ŒåŒ…å«ç”¨æˆ·æ¡£æ¡ˆå’Œå†å²
        user_message: ç”¨æˆ·æ¶ˆæ¯
        conversation_history: å¯é€‰çš„å¯¹è¯å†å²

    Returns:
        str: æ¨¡æ‹Ÿçš„AIå“åº”
    """
    # è·å–ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯
    profile = memory.get_profile_content()
    events = memory.get_event_content()
    insights = memory.get_mind_content()

    # åŸºäºç”¨æˆ·æ¶ˆæ¯ç±»å‹ç”Ÿæˆå“åº”
    user_msg_lower = user_message.lower()

    # å¦‚æœè¯¢é—®å†å²æˆ–è®°å¿†
    if any(word in user_msg_lower for word in ["è®°å¾—", "è¿˜è®°å¾—", "ä¹‹å‰", "å†å²", "ä»¥å‰"]):
        if events:
            recent_events = events[-3:]  # æœ€è¿‘3ä¸ªäº‹ä»¶
            return f"æ˜¯çš„ï¼Œæˆ‘è®°å¾—æˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡ï¼š{'; '.join(recent_events)}ã€‚åŸºäºè¿™äº›äº¤æµï¼Œæˆ‘äº†è§£åˆ°æ‚¨çš„éœ€æ±‚ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥è¿›ä¸€æ­¥å¸®åŠ©çš„å—ï¼Ÿ"
        else:
            return "è¿™æ˜¯æˆ‘ä»¬ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œä½†æˆ‘å¾ˆæœŸå¾…äº†è§£æ‚¨çš„éœ€æ±‚å¹¶ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼"

    # Pythonå­¦ä¹ ç›¸å…³
    if any(word in user_msg_lower for word in ["python", "ç¼–ç¨‹", "ä»£ç ", "å­¦ä¹ "]):
        if "åˆå­¦è€…" in user_msg_lower or any("åˆå­¦è€…" in insight for insight in insights):
            return "å¯¹äºPythonåˆå­¦è€…ï¼Œæˆ‘å»ºè®®ä»åŸºç¡€è¯­æ³•å¼€å§‹ï¼šå˜é‡ã€æ•°æ®ç±»å‹ã€æ§åˆ¶ç»“æ„ã€‚ç„¶åå­¦ä¹ å‡½æ•°å’Œé¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚å»ºè®®ä½¿ç”¨Pythonå®˜æ–¹æ•™ç¨‹å’Œå®è·µé¡¹ç›®æ¥å·©å›ºçŸ¥è¯†ã€‚"
        else:
            return "Pythonæ˜¯ä¸€é—¨å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ã€‚æ ¹æ®æ‚¨çš„å­¦ä¹ ç›®æ ‡ï¼Œæˆ‘å¯ä»¥æ¨èç›¸åº”çš„å­¦ä¹ è·¯å¾„ï¼šæ•°æ®ç§‘å­¦ã€Webå¼€å‘ã€è‡ªåŠ¨åŒ–è„šæœ¬ç­‰ã€‚æ‚¨æ›´æ„Ÿå…´è¶£å“ªä¸ªæ–¹å‘ï¼Ÿ"

    # æœºå™¨å­¦ä¹ ç›¸å…³
    if any(word in user_msg_lower for word in ["æœºå™¨å­¦ä¹ ", "ml", "ai", "äººå·¥æ™ºèƒ½", "ç®—æ³•"]):
        return "æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªæ¿€åŠ¨äººå¿ƒçš„é¢†åŸŸï¼å»ºè®®ä»ä»¥ä¸‹æ­¥éª¤å¼€å§‹ï¼š1) æŒæ¡Pythonå’Œæ•°å­¦åŸºç¡€ï¼Œ2) å­¦ä¹ NumPyã€Pandasã€Scikit-learnï¼Œ3) ç†è§£åŸºæœ¬ç®—æ³•ï¼Œ4) åŠ¨æ‰‹åšé¡¹ç›®ã€‚æ‚¨æƒ³äº†è§£å“ªä¸ªå…·ä½“æ–¹é¢ï¼Ÿ"

    # é¡¹ç›®ç›¸å…³
    if any(word in user_msg_lower for word in ["é¡¹ç›®", "å®æˆ˜", "ç»ƒä¹ ", "ä½œå“"]):
        skill_level = "åˆçº§" if any("åˆå­¦è€…" in insight for insight in insights) else "ä¸­çº§"
        if skill_level == "åˆçº§":
            return "æ¨èä¸€äº›é€‚åˆåˆå­¦è€…çš„é¡¹ç›®ï¼š1) è®¡ç®—å™¨ç¨‹åºï¼Œ2) å¾…åŠäº‹é¡¹ç®¡ç†å™¨ï¼Œ3) ç®€å•çš„æ•°æ®åˆ†æé¡¹ç›®ï¼Œ4) æ–‡æœ¬å¤„ç†å·¥å…·ã€‚è¿™äº›é¡¹ç›®èƒ½å¸®æ‚¨ç»ƒä¹ åŸºç¡€æ¦‚å¿µã€‚"
        else:
            return "å¯¹äºæœ‰ä¸€å®šåŸºç¡€çš„å¼€å‘è€…ï¼Œæ¨èï¼š1) Webåº”ç”¨ï¼ˆFlask/Djangoï¼‰ï¼Œ2) æ•°æ®ç§‘å­¦é¡¹ç›®ï¼Œ3) æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œ4) APIå¼€å‘ã€‚é€‰æ‹©ä¸æ‚¨å…´è¶£ç›¸å…³çš„æ–¹å‘æ·±å…¥ã€‚"

    # å·¥å…·å’Œåº“ç›¸å…³
    if any(word in user_msg_lower for word in ["numpy", "pandas", "tensorflow", "pytorch"]):
        if "numpy" in user_msg_lower or "pandas" in user_msg_lower:
            return "NumPyå’ŒPandasæ˜¯æ•°æ®ç§‘å­¦çš„åŸºç¡€åº“ã€‚NumPyæä¾›æ•°å€¼è®¡ç®—èƒ½åŠ›ï¼ŒPandasç”¨äºæ•°æ®å¤„ç†å’Œåˆ†æã€‚å»ºè®®å…ˆæŒæ¡Pandasï¼Œå› ä¸ºå®ƒåŒ…å«äº†NumPyçš„å¤§éƒ¨åˆ†åŠŸèƒ½ï¼Œæ›´é€‚åˆæ—¥å¸¸æ•°æ®å·¥ä½œã€‚"
        elif "tensorflow" in user_msg_lower or "pytorch" in user_msg_lower:
            return "TensorFlowå’ŒPyTorchéƒ½æ˜¯ä¼˜ç§€çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚å¯¹åˆå­¦è€…æ¥è¯´ï¼ŒPyTorchæ›´ç›´è§‚æ˜“å­¦ï¼ŒTensorFlowæ›´é€‚åˆç”Ÿäº§ç¯å¢ƒã€‚å»ºè®®ä»PyTorchå¼€å§‹å­¦ä¹ æ¦‚å¿µï¼Œç„¶åæ ¹æ®éœ€è¦å­¦ä¹ TensorFlowã€‚"

    # å·¥ä½œç›¸å…³
    if any(word in user_msg_lower for word in ["å·¥ä½œ", "å°±ä¸š", "èŒä¸š", "é¢è¯•", "æ±‚èŒ"]):
        tech_interests = any(
            keyword in " ".join(events + insights).lower()
            for keyword in ["python", "æœºå™¨å­¦ä¹ ", "ç¼–ç¨‹", "æŠ€æœ¯"]
        )
        if tech_interests:
            return "æ ¹æ®æ‚¨çš„æŠ€æœ¯èƒŒæ™¯ï¼Œå»ºè®®å‡†å¤‡ä»¥ä¸‹æ–¹é¢ï¼š1) å·©å›ºPythonåŸºç¡€å’Œé¡¹ç›®ç»éªŒï¼Œ2) å‡†å¤‡ç®—æ³•å’Œæ•°æ®ç»“æ„ï¼Œ3) å»ºç«‹GitHubä½œå“é›†ï¼Œ4) å­¦ä¹ ç›¸å…³æ¡†æ¶å’Œå·¥å…·ï¼Œ5) ç»ƒä¹ æŠ€æœ¯é¢è¯•é¢˜ã€‚ä¸“æ³¨äºæ‚¨æ„Ÿå…´è¶£çš„æŠ€æœ¯æ–¹å‘ã€‚"
        else:
            return "æ‰¾å·¥ä½œæ˜¯ä¸ªç³»ç»Ÿå·¥ç¨‹ï¼Œå»ºè®®ï¼š1) æ˜ç¡®èŒä¸šç›®æ ‡ï¼Œ2) å®Œå–„ç®€å†å’Œä½œå“é›†ï¼Œ3) æå‡ç›¸å…³æŠ€èƒ½ï¼Œ4) ç½‘ç»œå»ºè®¾å’ŒæŠ•é€’ç®€å†ï¼Œ5) é¢è¯•å‡†å¤‡ã€‚æˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„å…·ä½“æƒ…å†µæä¾›æ›´è¯¦ç»†çš„å»ºè®®ã€‚"

    # é»˜è®¤å“åº”
    if profile:
        return "æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ã€‚åŸºäºæˆ‘å¯¹æ‚¨çš„äº†è§£ï¼Œæˆ‘å»ºè®®ä»æ‚¨æ„Ÿå…´è¶£çš„é¢†åŸŸå¼€å§‹æ·±å…¥ã€‚æœ‰ä»€ä¹ˆå…·ä½“çš„æ–¹é¢éœ€è¦æˆ‘è¯¦ç»†è§£é‡Šå—ï¼Ÿ"
    else:
        return "æ„Ÿè°¢æ‚¨çš„é—®é¢˜ï¼æˆ‘å¾ˆä¹æ„å¸®åŠ©æ‚¨ã€‚è¯·å‘Šè¯‰æˆ‘æ›´å¤šèƒŒæ™¯ä¿¡æ¯ï¼Œè¿™æ ·æˆ‘èƒ½æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„å»ºè®®ã€‚"


def extract_events_from_conversation(messages: List[Dict[str, str]]) -> List[str]:
    """
    ä»å¯¹è¯æ¶ˆæ¯ä¸­æå–é‡è¦äº‹ä»¶

    Args:
        messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯åŒ…å«roleå’Œcontent

    Returns:
        List[str]: æå–çš„äº‹ä»¶åˆ—è¡¨
    """
    events = []

    # äº‹ä»¶å…³é”®è¯
    event_keywords = [
        "å­¦ä¹ ",
        "é—®é¢˜",
        "é¡¹ç›®",
        "å·¥ä½œ",
        "è´­ä¹°",
        "è®¡åˆ’",
        "å®Œæˆ",
        "å¼€å§‹",
        "å†³å®š",
        "ä½¿ç”¨",
        "å°è¯•",
        "åˆ›å»º",
        "å¼€å‘",
        "ç ”ç©¶",
        "åˆ†æ",
        "è®¾è®¡",
        "å®ç°",
    ]

    # å­¦ä¹ ç›¸å…³çš„ç‰¹æ®Šæ¨¡å¼
    learning_patterns = [
        r"å­¦ä¹ .*?([A-Za-z]+|[\u4e00-\u9fa5]+)",
        r"æƒ³è¦.*?å­¦ä¹ ",
        r"å¼€å§‹.*?å­¦ä¹ ",
        r"æ­£åœ¨.*?å­¦ä¹ ",
    ]

    for msg in messages:
        if msg["role"] == "user":
            content = msg["content"]

            # è·³è¿‡å¤ªçŸ­çš„æ¶ˆæ¯
            if len(content) < 10:
                continue

            # æ£€æŸ¥å­¦ä¹ æ¨¡å¼
            for pattern in learning_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    event = f"ç”¨æˆ·å¼€å§‹å­¦ä¹ {match}"
                    if event not in events:
                        events.append(event)

            # æ£€æŸ¥å…³é”®è¯äº‹ä»¶
            for keyword in event_keywords:
                if keyword in content:
                    # åˆ›å»ºäº‹ä»¶æè¿°ï¼Œæˆªå–å…³é”®éƒ¨åˆ†
                    if len(content) > 50:
                        # æ‰¾åˆ°å…³é”®è¯å‰åçš„ä¸Šä¸‹æ–‡
                        keyword_pos = content.find(keyword)
                        start = max(0, keyword_pos - 20)
                        end = min(len(content), keyword_pos + 30)
                        context = content[start:end].strip()
                        event = f"ç”¨æˆ·{keyword}ç›¸å…³: {context}"
                    else:
                        event = f"ç”¨æˆ·{keyword}ç›¸å…³: {content}"

                    if event not in events and len(event) > 10:
                        events.append(event)
                    break  # é¿å…ä¸€ä¸ªæ¶ˆæ¯äº§ç”Ÿå¤šä¸ªäº‹ä»¶

    return events[:5]  # æœ€å¤šè¿”å›5ä¸ªäº‹ä»¶


def extract_insights_from_conversation(
    messages: List[Dict[str, str]], current_insights: List[str] = None
) -> List[str]:
    """
    ä»å¯¹è¯æ¶ˆæ¯ä¸­æå–ç”¨æˆ·æ´å¯Ÿå’Œç‰¹å¾

    Args:
        messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        current_insights: å½“å‰å·²æœ‰çš„æ´å¯Ÿåˆ—è¡¨

    Returns:
        List[str]: æ–°çš„æ´å¯Ÿåˆ—è¡¨
    """
    if current_insights is None:
        current_insights = []

    insights = []

    # æå–æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯
    user_messages = [msg["content"] for msg in messages if msg["role"] == "user"]

    if len(user_messages) < 1:
        return insights

    # åˆ†ææ–‡æœ¬å†…å®¹
    all_user_text = " ".join(user_messages).lower()

    # æŠ€æœ¯å…´è¶£åˆ†æ
    technical_keywords = [
        "ä»£ç ",
        "ç¼–ç¨‹",
        "ç®—æ³•",
        "api",
        "æ•°æ®åº“",
        "æœºå™¨å­¦ä¹ ",
        "ai",
        "python",
        "java",
        "javascript",
    ]
    business_keywords = ["å·¥ä½œ", "é¡¹ç›®", "ç®¡ç†", "å›¢é˜Ÿ", "ä¸šåŠ¡", "è®¡åˆ’", "èŒä¸š", "å…¬å¸"]
    learning_keywords = ["å­¦ä¹ ", "æ•™ç¨‹", "æ€ä¹ˆ", "å¦‚ä½•", "æ–¹æ³•", "æ­¥éª¤", "äº†è§£", "æŒæ¡"]
    beginner_keywords = ["åˆå­¦è€…", "æ–°æ‰‹", "åˆšå¼€å§‹", "ä¸ä¼š", "ä¸æ‡‚", "åŸºç¡€"]
    advanced_keywords = ["é«˜çº§", "æ·±å…¥", "ä¼˜åŒ–", "æ¶æ„", "è®¾è®¡æ¨¡å¼", "æœ€ä½³å®è·µ"]

    # æ£€æŸ¥æŠ€æœ¯å…´è¶£
    tech_count = sum(1 for keyword in technical_keywords if keyword in all_user_text)
    if tech_count >= 2 and "ç”¨æˆ·å¯¹æŠ€æœ¯è¯é¢˜æ„Ÿå…´è¶£" not in current_insights:
        insights.append("ç”¨æˆ·å¯¹æŠ€æœ¯è¯é¢˜æ„Ÿå…´è¶£")

    # æ£€æŸ¥å•†ä¸šå…´è¶£
    business_count = sum(1 for keyword in business_keywords if keyword in all_user_text)
    if business_count >= 2 and "ç”¨æˆ·å…³æ³¨å·¥ä½œå’Œé¡¹ç›®ç®¡ç†" not in current_insights:
        insights.append("ç”¨æˆ·å…³æ³¨å·¥ä½œå’Œé¡¹ç›®ç®¡ç†")

    # æ£€æŸ¥å­¦ä¹ æ€åº¦
    learning_count = sum(1 for keyword in learning_keywords if keyword in all_user_text)
    if learning_count >= 2 and "ç”¨æˆ·ç§¯æä¸»åŠ¨å­¦ä¹ æ–°çŸ¥è¯†" not in current_insights:
        insights.append("ç”¨æˆ·ç§¯æä¸»åŠ¨å­¦ä¹ æ–°çŸ¥è¯†")

    # æ£€æŸ¥æŠ€èƒ½æ°´å¹³
    beginner_count = sum(1 for keyword in beginner_keywords if keyword in all_user_text)
    advanced_count = sum(1 for keyword in advanced_keywords if keyword in all_user_text)

    if beginner_count >= 1 and "ç”¨æˆ·å¤„äºå­¦ä¹ åˆæœŸé˜¶æ®µ" not in current_insights:
        insights.append("ç”¨æˆ·å¤„äºå­¦ä¹ åˆæœŸé˜¶æ®µ")
    elif advanced_count >= 1 and "ç”¨æˆ·å…·æœ‰ä¸€å®šæŠ€æœ¯åŸºç¡€" not in current_insights:
        insights.append("ç”¨æˆ·å…·æœ‰ä¸€å®šæŠ€æœ¯åŸºç¡€")

    # æ£€æŸ¥å…·ä½“æŠ€æœ¯å…´è¶£
    if "python" in all_user_text and "ç”¨æˆ·å¯¹Pythonç¼–ç¨‹æ„Ÿå…´è¶£" not in current_insights:
        insights.append("ç”¨æˆ·å¯¹Pythonç¼–ç¨‹æ„Ÿå…´è¶£")

    if (
        any(keyword in all_user_text for keyword in ["æœºå™¨å­¦ä¹ ", "ai", "ç®—æ³•"])
        and "ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ é¢†åŸŸæ„Ÿå…´è¶£" not in current_insights
    ):
        insights.append("ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ é¢†åŸŸæ„Ÿå…´è¶£")

    if (
        any(keyword in all_user_text for keyword in ["web", "ç½‘ç«™", "å‰ç«¯", "åç«¯"])
        and "ç”¨æˆ·å¯¹Webå¼€å‘æ„Ÿå…´è¶£" not in current_insights
    ):
        insights.append("ç”¨æˆ·å¯¹Webå¼€å‘æ„Ÿå…´è¶£")

    return insights


def analyze_user_interest_keywords(text: str) -> Dict[str, List[str]]:
    """
    åˆ†æç”¨æˆ·å…´è¶£å…³é”®è¯

    Args:
        text: è¦åˆ†æçš„æ–‡æœ¬

    Returns:
        Dict[str, List[str]]: æŒ‰ç±»åˆ«åˆ†ç»„çš„å…³é”®è¯
    """
    result = {"æŠ€æœ¯": [], "ä¸šåŠ¡": [], "å­¦ä¹ ": [], "å·¥å…·": []}

    # å®šä¹‰å…³é”®è¯åº“
    keywords_map = {
        "æŠ€æœ¯": ["ç¼–ç¨‹", "ä»£ç ", "ç®—æ³•", "æ•°æ®ç»“æ„", "è®¾è®¡æ¨¡å¼", "æ¶æ„", "API", "æ•°æ®åº“"],
        "ä¸šåŠ¡": ["é¡¹ç›®", "ç®¡ç†", "å›¢é˜Ÿ", "ä¸šåŠ¡", "äº§å“", "ç”¨æˆ·", "éœ€æ±‚", "å·¥ä½œæµ"],
        "å­¦ä¹ ": ["æ•™ç¨‹", "æ–‡æ¡£", "ä¹¦ç±", "è¯¾ç¨‹", "ç»ƒä¹ ", "å®è·µ", "ç»éªŒ", "æŠ€èƒ½"],
        "å·¥å…·": ["python", "java", "javascript", "react", "django", "mysql", "git", "docker"],
    }

    text_lower = text.lower()

    for category, keywords in keywords_map.items():
        for keyword in keywords:
            if keyword in text_lower:
                result[category].append(keyword)

    return result


def generate_learning_path_suggestions(insights: List[str], events: List[str]) -> List[str]:
    """
    åŸºäºç”¨æˆ·æ´å¯Ÿå’Œäº‹ä»¶ç”Ÿæˆå­¦ä¹ è·¯å¾„å»ºè®®

    Args:
        insights: ç”¨æˆ·æ´å¯Ÿåˆ—è¡¨
        events: ç”¨æˆ·äº‹ä»¶åˆ—è¡¨

    Returns:
        List[str]: å­¦ä¹ è·¯å¾„å»ºè®®
    """
    suggestions = []

    # åˆ†æç”¨æˆ·æ°´å¹³
    is_beginner = any("åˆæœŸ" in insight or "åˆå­¦è€…" in insight for insight in insights)
    has_tech_interest = any("æŠ€æœ¯" in insight for insight in insights)
    loves_python = any("Python" in insight for insight in insights)
    loves_ml = any("æœºå™¨å­¦ä¹ " in insight for insight in insights)

    if is_beginner and has_tech_interest:
        suggestions.extend(
            [
                "å»ºè®®ä»PythonåŸºç¡€è¯­æ³•å¼€å§‹å­¦ä¹ ",
                "æŒæ¡åŸºæœ¬çš„æ•°æ®ç±»å‹å’Œæ§åˆ¶ç»“æ„",
                "å­¦ä¹ å‡½æ•°å®šä¹‰å’Œä½¿ç”¨",
                "ç»ƒä¹ ç®€å•çš„ç¼–ç¨‹é¡¹ç›®",
            ]
        )

    if loves_python:
        if is_beginner:
            suggestions.extend(
                ["å®ŒæˆPythonå®˜æ–¹æ•™ç¨‹", "å­¦ä¹ Pythonæ ‡å‡†åº“çš„å¸¸ç”¨æ¨¡å—", "å°è¯•ç¼–å†™å°å·¥å…·å’Œè„šæœ¬"]
            )
        else:
            suggestions.extend(
                [
                    "æ·±å…¥å­¦ä¹ Pythoné«˜çº§ç‰¹æ€§",
                    "æŒæ¡é¢å‘å¯¹è±¡ç¼–ç¨‹å’Œè®¾è®¡æ¨¡å¼",
                    "å­¦ä¹ Python Webæ¡†æ¶ï¼ˆFlask/Djangoï¼‰",
                ]
            )

    if loves_ml:
        prerequisites = ["æŒæ¡PythonåŸºç¡€", "å­¦ä¹ NumPyå’ŒPandas", "äº†è§£åŸºæœ¬ç»Ÿè®¡æ¦‚å¿µ"]
        ml_path = ["å­¦ä¹ Scikit-learnåŸºç¡€", "ç†è§£ç›‘ç£å­¦ä¹ ç®—æ³•", "å®è·µæœºå™¨å­¦ä¹ é¡¹ç›®"]

        if is_beginner:
            suggestions.extend(prerequisites + ml_path)
        else:
            suggestions.extend(ml_path + ["æ·±å…¥å­¦ä¹ æ·±åº¦å­¦ä¹ æ¡†æ¶", "å‚ä¸å¼€æºMLé¡¹ç›®"])

    # å»é‡å¹¶é™åˆ¶æ•°é‡
    unique_suggestions = []
    for suggestion in suggestions:
        if suggestion not in unique_suggestions:
            unique_suggestions.append(suggestion)

    return unique_suggestions[:8]  # æœ€å¤š8ä¸ªå»ºè®®


def format_conversation_summary(messages: List[Dict[str, str]], max_length: int = 100) -> str:
    """
    æ ¼å¼åŒ–å¯¹è¯æ‘˜è¦

    Args:
        messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        max_length: æ‘˜è¦æœ€å¤§é•¿åº¦

    Returns:
        str: æ ¼å¼åŒ–çš„å¯¹è¯æ‘˜è¦
    """
    if not messages:
        return "Empty conversation"

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ä½œä¸ºå¯¹è¯ä¸»é¢˜
    first_user_msg = None
    for msg in messages:
        if msg["role"] == "user":
            first_user_msg = msg["content"]
            break

    if not first_user_msg:
        return f"Conversation with {len(messages)} turns"

    # åˆ›å»ºæ‘˜è¦
    turn_count = len([msg for msg in messages if msg["role"] == "user"])
    summary = f"Conversation with {turn_count} turns: {first_user_msg}"

    # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
    if len(summary) > max_length:
        summary = summary[: max_length - 3] + "..."

    return summary


def validate_conversation_data(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    éªŒè¯å¯¹è¯æ•°æ®çš„å®Œæ•´æ€§å’Œæ ¼å¼

    Args:
        messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨

    Returns:
        Dict[str, Any]: éªŒè¯ç»“æœï¼ŒåŒ…å«is_validå’Œerrors
    """
    result = {"is_valid": True, "errors": [], "warnings": []}

    if not messages:
        result["is_valid"] = False
        result["errors"].append("å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º")
        return result

    for i, msg in enumerate(messages):
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not isinstance(msg, dict):
            result["is_valid"] = False
            result["errors"].append(f"æ¶ˆæ¯ {i}: ä¸æ˜¯å­—å…¸æ ¼å¼")
            continue

        if "role" not in msg:
            result["is_valid"] = False
            result["errors"].append(f"æ¶ˆæ¯ {i}: ç¼ºå°‘roleå­—æ®µ")

        if "content" not in msg:
            result["is_valid"] = False
            result["errors"].append(f"æ¶ˆæ¯ {i}: ç¼ºå°‘contentå­—æ®µ")

        # æ£€æŸ¥roleå€¼
        if msg.get("role") not in ["user", "assistant", "system"]:
            result["warnings"].append(f"æ¶ˆæ¯ {i}: roleå€¼ä¸æ ‡å‡†: {msg.get('role')}")

        # æ£€æŸ¥å†…å®¹é•¿åº¦
        content = msg.get("content", "")
        if len(content) > 10000:
            result["warnings"].append(f"æ¶ˆæ¯ {i}: å†…å®¹è¿‡é•¿ ({len(content)} å­—ç¬¦)")
        elif len(content.strip()) == 0:
            result["warnings"].append(f"æ¶ˆæ¯ {i}: å†…å®¹ä¸ºç©º")

    return result


# ===== Memoryç®¡ç†å·¥å…·å‡½æ•° =====


def create_memory_manager():
    """åˆ›å»ºMemoryç®¡ç†å™¨ (PostgreSQL-only)"""

    db_manager = get_database_manager()
    return MemoryClient(db_manager=db_manager)


def create_conversation_manager(enable_embeddings: bool = True):
    """åˆ›å»ºå¯¹è¯ç®¡ç†å™¨ (PostgreSQL-only)

    Args:
        enable_embeddings: æ˜¯å¦å¯ç”¨å‘é‡åµŒå…¥
    """

    db_manager = get_database_manager()
    return ConversationManager(db_manager=db_manager, enable_embeddings=enable_embeddings)


def setup_agent_memory(memory_manager, agent_id: str, initial_profile: str = ""):
    """è®¾ç½®agentçš„åˆå§‹è®°å¿†"""
    memory = memory_manager.get_memory_by_agent(agent_id)
    if initial_profile:
        memory.update_profile(initial_profile)
        memory_manager.database.save_memory(memory)
    return memory


def get_memory_context(memory_manager, agent_id: str) -> str:
    """è·å–è®°å¿†ä¸Šä¸‹æ–‡ç”¨äºAIæç¤º"""
    memory = memory_manager.get_memory_by_agent(agent_id)
    context_parts = []

    # æ·»åŠ ç”¨æˆ·æ¡£æ¡ˆ
    profile = memory.get_profile_content()
    if profile:
        context_parts.append(f"ç”¨æˆ·èƒŒæ™¯ï¼š{profile}")

    # æ·»åŠ é‡è¦äº‹ä»¶
    events = memory.get_event_content()
    if events:
        recent_events = events[-3:]  # æœ€è¿‘3ä¸ªäº‹ä»¶
        context_parts.append("é‡è¦äº‹ä»¶ï¼š" + "ï¼›".join(recent_events))

    # æ·»åŠ ç”¨æˆ·æ´å¯Ÿ
    insights = memory.get_mind_content()
    if insights:
        recent_insights = insights[-2:]  # æœ€è¿‘2ä¸ªæ´å¯Ÿ
        context_parts.append("ç”¨æˆ·ç‰¹å¾ï¼š" + "ï¼›".join(recent_insights))

    return "\n\n".join(context_parts)


def get_conversation_context(
    conversation_manager, agent_id: str, query: str, limit: int = 2
) -> str:
    """è·å–ç›¸å…³çš„å†å²å¯¹è¯ä¸Šä¸‹æ–‡"""
    try:
        # æœç´¢ç›¸å…³å¯¹è¯
        results = conversation_manager.search_similar_conversations(
            agent_id=agent_id, query=query, limit=limit, similarity_threshold=0.6
        )

        if not results:
            return ""

        # æ„å»ºä¸Šä¸‹æ–‡
        context = "## ç›¸å…³å†å²å¯¹è¯\n"
        for i, result in enumerate(results, 1):
            context += f"{i}. {result['summary']}\n"

        context += "\nè¯·å‚è€ƒä»¥ä¸Šå†å²å¯¹è¯æ¥å›ç­”å½“å‰é—®é¢˜ã€‚"
        return context

    except Exception as e:
        print(f"âš ï¸ æ£€ç´¢å†å²å¤±è´¥: {e}")
        return ""


def build_system_prompt(
    memory_manager, conversation_manager, agent_id: str, user_message: str
) -> str:
    """æ„å»ºåŒ…å«è®°å¿†çš„ç³»ç»Ÿæç¤º"""
    base_prompt = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿè®°ä½ç”¨æˆ·çš„åå¥½å’Œå†å²å¯¹è¯ã€‚"

    # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
    memory_context = get_memory_context(memory_manager, agent_id)
    if memory_context:
        base_prompt += f"\n\n{memory_context}"

    # æ·»åŠ å¯¹è¯å†å²ä¸Šä¸‹æ–‡
    conversation_context = get_conversation_context(conversation_manager, agent_id, user_message)
    if conversation_context:
        base_prompt += f"\n\n{conversation_context}"

    return base_prompt


def learn_from_conversation(
    memory_manager,
    conversation_manager,
    agent_id: str,
    user_id: str,
    messages: List[Dict[str, str]],
    session_id: Optional[str] = None,
):
    """ä»å¯¹è¯ä¸­å­¦ä¹ å¹¶æ›´æ–°è®°å¿†"""
    try:
        # 1. è®°å½•å¯¹è¯
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        conversation_manager.record_conversation(
            agent_id=agent_id, user_id=user_id, messages=messages, session_id=session_id
        )

        # 2. æå–å­¦ä¹ å†…å®¹
        memory = memory_manager.get_memory_by_agent(agent_id)
        events = extract_events_from_conversation(messages)
        insights = extract_insights_from_conversation(messages, memory.get_mind_content())

        # 3. æ›´æ–°è®°å¿†
        updated = False
        if events:
            memory.update_events(events)
            print(f"ğŸ“ å­¦ä¹ åˆ°äº‹ä»¶: {len(events)} ä¸ª")
            updated = True

        if insights:
            memory.update_mind(insights)
            print(f"ğŸ§  è·å¾—æ´å¯Ÿ: {len(insights)} ä¸ª")
            updated = True

        # 4. ä¿å­˜è®°å¿†
        if updated:
            memory_manager.database.save_memory(memory)

        return updated

    except Exception as e:
        print(f"âŒ å­¦ä¹ å¤±è´¥: {e}")
        return False


def get_memory_summary(memory_manager, agent_id: str) -> Dict[str, Any]:
    """è·å–è®°å¿†æ‘˜è¦"""
    memory = memory_manager.get_memory_by_agent(agent_id)

    return {
        "agent_id": agent_id,
        "profile": memory.get_profile_content(),
        "events": memory.get_event_content(),
        "insights": memory.get_mind_content(),
    }


def cleanup_memory_resources(memory_manager, conversation_manager):
    """æ¸…ç†èµ„æº"""
    try:
        if hasattr(memory_manager, "close"):
            memory_manager.close()
        if hasattr(conversation_manager, "close"):
            conversation_manager.close()
    except Exception:
        pass


def chat_with_memory(llm_client, memory: Memory, message: str, agent_id: str, user_id: str) -> str:
    """ä¸€ä½“åŒ–è®°å¿†èŠå¤©å‡½æ•°

    Args:
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        memory: è®°å¿†å¯¹è±¡
        message: ç”¨æˆ·æ¶ˆæ¯
        agent_id: æ™ºèƒ½ä½“ID (required)
        user_id: ç”¨æˆ·ID (required)

    Returns:
        AIå›å¤
    """
    # è·å–è®°å¿†ä¸Šä¸‹æ–‡
    # è·å–è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆæš‚æ—¶ä¸ä½¿ç”¨statsï¼‰

    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    memory_context = []
    if memory.get_profile():
        memory_context.append(f"ç”¨æˆ·æ¡£æ¡ˆ: {', '.join(memory.get_profile())}")
    if memory.get_events():
        memory_context.append(f"é‡è¦äº‹ä»¶: {', '.join(memory.get_events())}")
    if memory.get_mind():
        memory_context.append(f"å¿ƒç†æ´å¯Ÿ: {', '.join(memory.get_mind())}")

    system_prompt = """ä½ æ˜¯æ™ºèƒ½ä½“ {agent_id}ï¼Œæ­£åœ¨ä¸ç”¨æˆ· {user_id} å¯¹è¯ã€‚

è®°å¿†ä¸Šä¸‹æ–‡ï¼š
{chr(10).join(memory_context) if memory_context else 'æš‚æ— è®°å¿†ä¿¡æ¯'}

è¯·åŸºäºä»¥ä¸Šè®°å¿†ä¿¡æ¯ï¼Œä»¥è‡ªç„¶ã€æœ‰å¸®åŠ©çš„æ–¹å¼å›å¤ç”¨æˆ·ã€‚"""

    # å‘é€è¯·æ±‚
    response = llm_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message},
        ],
    )

    return response.choices[0].message.content
